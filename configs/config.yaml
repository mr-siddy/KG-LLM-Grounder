training:
  batch_size: 4
  learning_rate: 1e-5
  epochs: 3
  max_seq_length: 512
  grad_accum_steps: 4
  logging_steps: 100         # Log every 100 steps
  save_steps: 500            # Save checkpoint every 500 steps
  eval_steps: 100            # Evaluate every 100 steps
  max_grad_norm: 1.0         # For gradient clipping
  fp16: false                # Set to true if using mixed precision training

model:
  name_or_path: "meta-llama/Llama-3.2-1B"
  trust_remote_code: true

data:
  train_file: "../data/train.json"
  val_file: "../data/val.json"
  kg_file: "../data/kg_triples.tsv"

kg:
  embedding_dim: 128
  num_epochs: 50
  model_name: "TransE"
  lambda_kg: 1.0            # Optional scaling factor for KG fusion

output:
  save_dir: "checkpoints/"
